{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Setup\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# %pip install seaborn\n",
    "# import piplite\n",
    "#\n",
    "# await piplite.install(['nbformat', 'plotly'])"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T15:01:17.845488Z",
     "start_time": "2025-04-18T15:01:17.838104Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "URL= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T15:01:17.980833Z",
     "start_time": "2025-04-18T15:01:17.890597Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# from pyodide.http import pyfetch\n",
    "#\n",
    "# async def download(url, filename):\n",
    "#     response = await pyfetch(url)\n",
    "#     if response.status == 200:\n",
    "#         with open(filename, \"wb\") as f:\n",
    "#             f.write(await response.bytes())\n",
    "\n",
    "path = URL\n",
    "\n",
    "# await download(path, \"dataset.csv\")"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T15:01:18.154040Z",
     "start_time": "2025-04-18T15:01:18.145086Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "---\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Test Environment\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\n",
    "\n",
    "# Specify the file path\n",
    "file_path = path\n",
    "\n",
    "# Read the CSV file into a Pandas data frame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Assuming the first rows of the file are the headers, you don't need to specify any additional parameters\n",
    "\n",
    "# Additional details:\n",
    "# - The `pd.read_csv()` function is used to read a CSV file into a Pandas data frame.\n",
    "# - By default, it assumes that the first row of the file contains the headers for the data.\n",
    "# - If your file doesn't have headers, you can specify `header=None` as an additional parameter.\n",
    "# - You can also specify other parameters, such as `sep` to specify the delimiter used in the file.\n",
    "# - Make sure you have the Pandas library installed in your Python environment before running this code.\n",
    "\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Identify columns with missing values\n",
    "columns_with_missing_values = df.columns[df.isnull().any()]\n",
    "\n",
    "# Additional details:\n",
    "# - The `df.isnull()` function returns a Boolean data frame where each cell is True if it contains a missing value (NaN), and False otherwise.\n",
    "# - The `df.columns` attribute returns the column labels of the data frame.\n",
    "# - The `.any()` method returns a Boolean Series indicating whether any value in the given axis (in this case, columns) is True.\n",
    "# - Finally, the `.columns` attribute is used to retrieve the column labels where the condition is True.\n",
    "\n",
    "# You can now use the 'columns_with_missing_values' variable to further analyze or handle the columns with missing values.\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Replace missing values in the 'Screen_Size_cm' column with the most frequent value\n",
    "most_frequent_value = df['Screen_Size_cm'].mode()[0]\n",
    "df['Screen_Size_cm'].fillna(most_frequent_value, inplace=False)\n",
    "\n",
    "# Replace missing values in the 'Weight_kg' column with the mean value\n",
    "mean_value = df['Weight_kg'].mean()\n",
    "df['Weight_kg'].fillna(mean_value, inplace=False)\n",
    "\n",
    "# Additional details:\n",
    "# - The `.mode()` method is used to calculate the most frequent value in a column.\n",
    "# - The `[0]` indexing is used to retrieve the most frequent value from the resulting Series.\n",
    "# - The `.fillna()` method is used to replace missing values with a specified value.\n",
    "# - The `inplace=True` parameter is used to modify the original data frame instead of creating a new one.\n",
    "\n",
    "# You can now use the modified 'df' data frame, which has the missing values replaced according to the guidelines.\n",
    "\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Change the data type of 'Screen_Size_cm' and 'Weight_kg' to float\n",
    "df['Screen_Size_cm'] = df['Screen_Size_cm'].astype(float)\n",
    "df['Weight_kg'] = df['Weight_kg'].astype(float)\n",
    "\n",
    "# Additional details:\n",
    "# - The `.astype()` method is used to change the data type of a column.\n",
    "# - In this case, we're specifying `float` as the desired data type.\n",
    "# - Make sure the columns contain numeric values that can be converted to float.\n",
    "# - If there are any non-numeric values in the columns, the conversion will raise an error.\n",
    "\n",
    "# You can now use the modified 'df' data frame, which has the data types of 'Screen_Size_cm' and 'Weight_kg' changed to float.\n",
    "\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Convert 'Screen_Size_cm' from centimeters to inches and modify the attribute name\n",
    "df['Screen_Size_inch'] = df['Screen_Size_cm'] * 0.393701\n",
    "df.drop('Screen_Size_cm', axis=1, inplace=False)\n",
    "\n",
    "# Convert 'Weight_kg' from kilograms to pounds and modify the attribute name\n",
    "df['Weight_pounds'] = df['Weight_kg'] * 2.20462\n",
    "df.drop('Weight_kg', axis=1, inplace=False)\n",
    "\n",
    "# Additional details:\n",
    "# - The code multiplies the values under 'Screen_Size_cm' by 0.393701 to convert centimeters to inches.\n",
    "# - The resulting values are stored in a new attribute named 'Screen_Size_inch'.\n",
    "# - The original 'Screen_Size_cm' attribute is dropped from the data frame using the `.drop()` method.\n",
    "# - Similarly, the code multiplies the values under 'Weight_kg' by 2.20462 to convert kilograms to pounds.\n",
    "# - The resulting values are stored in a new attribute named 'Weight_pounds'.\n",
    "# - The original 'Weight_kg' attribute is dropped from the data frame.\n",
    "\n",
    "# You can now use the modified 'df' data frame, which has the contents and attribute names modified as required.\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Normalize the content under 'CPU_frequency' with respect to its maximum value\n",
    "max_value = df['CPU_frequency'].max()\n",
    "df['CPU_frequency'] = df['CPU_frequency'] / max_value\n",
    "\n",
    "# Additional details:\n",
    "# - The code calculates the maximum value of the 'CPU_frequency' attribute using the `.max()` method.\n",
    "# - It then divides the values under 'CPU_frequency' by the maximum value to normalize them.\n",
    "# - The resulting normalized values overwrite the original values in the 'CPU_frequency' attribute.\n",
    "\n",
    "# You can now use the modified 'df' data frame, which has the content under the 'CPU_frequency' attribute normalized.\n",
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "\n",
    "# Convert the 'Screen' attribute into indicator variables\n",
    "df1 = pd.get_dummies(df['Screen'], prefix='Screen')\n",
    "\n",
    "# Append df1 into the original data frame df\n",
    "df = pd.concat([df, df1], axis=1)\n",
    "\n",
    "# Drop the original 'Screen' attribute from the data frame\n",
    "df.drop('Screen', axis=1, inplace=False)\n",
    "\n",
    "# Additional details:\n",
    "# - The `pd.get_dummies()` function is used to convert a categorical attribute into indicator variables.\n",
    "# - The resulting indicator variables are stored in a new data frame named 'df1'.\n",
    "# - The `prefix` parameter is used to specify the naming convention for the indicator variables.\n",
    "# - The `pd.concat()` function is used to concatenate the original data frame 'df' and 'df1' along the column axis (axis=1).\n",
    "# - The resulting concatenated data frame is assigned back to 'df'.\n",
    "# - Finally, the `.drop()` method is used to drop the original 'Screen' attribute from 'df'.\n",
    "\n",
    "# You can now use the modified 'df' data frame, which has the 'Screen' attribute converted into indicator variables, appended, and the original attribute dropped.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def train_linear_regression(data, feature_col, target_col):\n",
    "    \"\"\"\n",
    "    Trains a linear regression model on given data.\n",
    "\n",
    "    :param data: pandas DataFrame containing the data\n",
    "    :param feature_col: str, name of the column to use as predictor\n",
    "    :param target_col: str, name of the column to use as the target variable\n",
    "    :return: tuple (trained model, mse, r2_score)\n",
    "    \"\"\"\n",
    "    # Prepare features (X) and target (y)\n",
    "    x = data[feature_col]\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the linear regression model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = lr.predict(x_test)\n",
    "\n",
    "    # Calculate MSE and R^2\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return lr, mse, r2\n",
    "\n",
    "# Example data frame (this part should be replaced with actual data)\n",
    "# target = df['Price']\n",
    "# feature = df.drop('Price', axis=1)\n",
    "# data = pd.DataFrame({\n",
    "#     'feature': feature,\n",
    "#     'target': target\n",
    "# })\n",
    "\n",
    "# Columns to use\n",
    "# data = df\n",
    "df = df.dropna(axis= 0, how='any')\n",
    "target =df['Price']\n",
    "feature =df.drop(columns=['Price','Unnamed: 0','Manufacturer','Screen'], axis=1)\n",
    "feature_names = feature.columns.tolist()\n",
    "print(feature_names)\n",
    "print(df.head())\n",
    "\n",
    "# Train the model\n",
    "model, msq, R2 = train_linear_regression(df,feature_names,'Price')\n",
    "\n",
    "# # Output results\n",
    "print(f\"Mean Squared Error (MSE): {msq}\")\n",
    "print(f\"R^2 Score: {R2}\")"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T16:15:15.628109Z",
     "start_time": "2025-04-18T16:15:13.323850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category', 'GPU', 'OS', 'CPU_core', 'Screen_Size_cm', 'CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'Weight_kg', 'Screen_Size_inch', 'Weight_pounds', 'Screen_Full HD', 'Screen_IPS Panel']\n",
      "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n",
      "0           0         Acer         4  IPS Panel    2   1         5   \n",
      "1           1         Dell         3    Full HD    1   1         3   \n",
      "2           2         Dell         3    Full HD    1   1         7   \n",
      "3           3         Dell         4  IPS Panel    2   1         5   \n",
      "4           4           HP         4    Full HD    2   1         7   \n",
      "\n",
      "   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \\\n",
      "0          35.560       0.551724       8             256       1.60    978   \n",
      "1          39.624       0.689655       4             256       2.20    634   \n",
      "2          39.624       0.931034       8             256       2.20    946   \n",
      "3          33.782       0.551724       8             128       1.22   1244   \n",
      "4          39.624       0.620690       8             256       1.91    837   \n",
      "\n",
      "   Screen_Size_inch  Weight_pounds  Screen_Full HD  Screen_IPS Panel  \n",
      "0         14.000008       3.527392           False              True  \n",
      "1         15.600008       4.850164            True             False  \n",
      "2         15.600008       4.850164            True             False  \n",
      "3         13.300007       2.689636           False              True  \n",
      "4         15.600008       4.210824            True             False  \n",
      "Mean Squared Error (MSE): 178008.75725173944\n",
      "R^2 Score: 0.5311140389962621\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": "## Authors\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Change Log\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
   "metadata": {}
  }
 ]
}
